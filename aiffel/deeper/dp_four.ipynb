{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim1987/aiffel/blob/main/aiffel/deeper/dp_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4AwUwmjP_L0k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import AG_NEWS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hUmBx8G-3fqW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3gHKMWdil8Cc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9hE2kpGJibsU"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WnyvuoV3ivbo"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "staL6qdAjAyt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MlpynnROkrb3"
      },
      "outputs": [],
      "source": [
        "def make_dtm(reuters,num_words=10000):\n",
        "  (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2,maxlen=512)\n",
        "  word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "  index_to_word = { index+3 : word for word, index in word_index.items() }\n",
        "  for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "    index_to_word[index]=token\n",
        "\n",
        "  decoded = []\n",
        "  for i in range(len(x_train)):\n",
        "      t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
        "      decoded.append(t)\n",
        "  x_train_de = decoded\n",
        "\n",
        "  decoded = []\n",
        "  for i in range(len(x_test)):\n",
        "      t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
        "      decoded.append(t)\n",
        "  x_test_de = decoded\n",
        "\n",
        "  dtmvector = CountVectorizer()\n",
        "  x_train_dtm = dtmvector.fit_transform(x_train_de)\n",
        "  x_test_dtm = dtmvector.transform(x_test_de)\n",
        "\n",
        "  tfidf_transformer = TfidfTransformer()\n",
        "  tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
        "  tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
        "  \n",
        "  return (x_train,tfidfv,y_train),(x_test,tfidfv_test,y_test),(word_index,index_to_word)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U9WKmDowlCGI"
      },
      "outputs": [],
      "source": [
        "def make_my_series(num_words):\n",
        "  (x_train,tfidfv,y_train),(x_test,tfidfv_test,y_test),_ = make_dtm(reuters,num_words)\n",
        "  row_data =pd.Series(name=str(num_words))\n",
        "\n",
        "  models=[MultinomialNB(),ComplementNB(),LogisticRegression(C=10000, penalty='l2'),LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False),\n",
        "          DecisionTreeClassifier(max_depth=10, random_state=0),RandomForestClassifier(n_estimators=5, random_state=0),GradientBoostingClassifier(random_state=0),\n",
        "          VotingClassifier(estimators=[('lr', LogisticRegression(C=10000, penalty='l2')),\n",
        "                                       ('cb', ComplementNB()),\n",
        "                                       ('grbt', GradientBoostingClassifier(random_state=0))\n",
        "                                      ], voting='soft', n_jobs=-1)\n",
        "          ]\n",
        "  names =['naive','Complement Naive','logistic','Linear SVC','DecisionTree','RandomForest','GradientBoosting','Voting']\n",
        "\n",
        "\n",
        "  for name,model in zip(names,models):\n",
        "    m_model= model\n",
        "    m_model.fit(tfidfv, y_train)\n",
        "    predicted = m_model.predict(tfidfv_test)\n",
        "    row_data[name]=accuracy_score(y_test, predicted)\n",
        "    \n",
        "  #tensorflow model\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=num_words,\n",
        "        output_dim=64,\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(46)\n",
        "    ])\n",
        "  \n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "  x_train=tf.keras.preprocessing.sequence.pad_sequences(x_train,maxlen=512,padding='post')\n",
        "  x_test=tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen=512,padding='post')\n",
        "\n",
        "  model.fit(x_train,y_train)#,epochs=10,batch_size=64\n",
        "  loss,accuracy = model.evaluate(x_test,y_test,batch_size=64)\n",
        "  row_data['lstm'] = accuracy\n",
        "\n",
        "  model.fit(x_train,y_train,epochs=9,batch_size=64)\n",
        "  loss,accuracy = model.evaluate(x_test,y_test,batch_size=64)\n",
        "  row_data['lstm_epoch'] = accuracy\n",
        "\n",
        "  return row_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uCqMnBPktORZ"
      },
      "outputs": [],
      "source": [
        "my_chart = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB-UgGeWvrv4",
        "outputId": "6aa3b3e4-21ca-49ba-b375-32ca983c5e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 207s 732ms/step - loss: 2.7684 - accuracy: 0.3706\n",
            "34/34 [==============================] - 11s 228ms/step - loss: 2.0213 - accuracy: 0.5088\n",
            "Epoch 1/9\n",
            "136/136 [==============================] - 134s 985ms/step - loss: 1.9549 - accuracy: 0.5067\n",
            "Epoch 2/9\n",
            "136/136 [==============================] - 134s 983ms/step - loss: 1.8065 - accuracy: 0.5225\n",
            "Epoch 3/9\n",
            "136/136 [==============================] - 134s 984ms/step - loss: 1.7021 - accuracy: 0.5615\n",
            "Epoch 4/9\n",
            "136/136 [==============================] - 133s 981ms/step - loss: 1.8051 - accuracy: 0.5069\n",
            "Epoch 5/9\n",
            "136/136 [==============================] - 134s 983ms/step - loss: 1.7135 - accuracy: 0.5479\n",
            "Epoch 6/9\n",
            "136/136 [==============================] - 134s 982ms/step - loss: 1.6687 - accuracy: 0.5627\n",
            "Epoch 7/9\n",
            "136/136 [==============================] - 134s 983ms/step - loss: 1.6260 - accuracy: 0.5896\n",
            "Epoch 8/9\n",
            "136/136 [==============================] - 133s 981ms/step - loss: 1.6023 - accuracy: 0.5971\n",
            "Epoch 9/9\n",
            "136/136 [==============================] - 134s 983ms/step - loss: 1.5799 - accuracy: 0.6000\n",
            "34/34 [==============================] - 8s 227ms/step - loss: 1.6745 - accuracy: 0.5870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 212s 751ms/step - loss: 2.8036 - accuracy: 0.3808\n",
            "34/34 [==============================] - 11s 231ms/step - loss: 2.0406 - accuracy: 0.4445\n",
            "Epoch 1/9\n",
            "136/136 [==============================] - 137s 1s/step - loss: 1.8827 - accuracy: 0.4877\n",
            "Epoch 2/9\n",
            "136/136 [==============================] - 137s 1s/step - loss: 1.7497 - accuracy: 0.5294\n",
            "Epoch 3/9\n",
            "136/136 [==============================] - 137s 1s/step - loss: 1.6687 - accuracy: 0.5707\n",
            "Epoch 4/9\n",
            "136/136 [==============================] - 136s 1s/step - loss: 1.6134 - accuracy: 0.5895\n",
            "Epoch 5/9\n",
            "136/136 [==============================] - 137s 1s/step - loss: 1.5470 - accuracy: 0.6006\n",
            "Epoch 6/9\n",
            "136/136 [==============================] - 136s 1s/step - loss: 1.4945 - accuracy: 0.6155\n",
            "Epoch 7/9\n",
            "136/136 [==============================] - 136s 1s/step - loss: 1.4303 - accuracy: 0.6407\n",
            "Epoch 8/9\n",
            "136/136 [==============================] - 136s 1s/step - loss: 1.3753 - accuracy: 0.6563\n",
            "Epoch 9/9\n",
            "136/136 [==============================] - 137s 1s/step - loss: 1.3424 - accuracy: 0.6589\n",
            "34/34 [==============================] - 8s 236ms/step - loss: 1.4814 - accuracy: 0.6327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 215s 762ms/step - loss: 2.7996 - accuracy: 0.3766\n",
            "34/34 [==============================] - 11s 229ms/step - loss: 2.0077 - accuracy: 0.5190\n",
            "Epoch 1/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.9626 - accuracy: 0.5108\n",
            "Epoch 2/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.8046 - accuracy: 0.5188\n",
            "Epoch 3/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.6761 - accuracy: 0.5687\n",
            "Epoch 4/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6182 - accuracy: 0.5858\n",
            "Epoch 5/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6675 - accuracy: 0.5553\n",
            "Epoch 6/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.5761 - accuracy: 0.5923\n",
            "Epoch 7/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.5522 - accuracy: 0.6001\n",
            "Epoch 8/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.5343 - accuracy: 0.6014\n",
            "Epoch 9/9\n",
            "136/136 [==============================] - 139s 1s/step - loss: 1.5238 - accuracy: 0.6055\n",
            "34/34 [==============================] - 8s 243ms/step - loss: 1.6659 - accuracy: 0.5772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "271/271 [==============================] - 216s 765ms/step - loss: 2.8045 - accuracy: 0.3629\n",
            "34/34 [==============================] - 10s 224ms/step - loss: 2.0840 - accuracy: 0.4570\n",
            "Epoch 1/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 2.0062 - accuracy: 0.4820\n",
            "Epoch 2/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.8905 - accuracy: 0.5030\n",
            "Epoch 3/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.7552 - accuracy: 0.5412\n",
            "Epoch 4/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6734 - accuracy: 0.5769\n",
            "Epoch 5/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6341 - accuracy: 0.5845\n",
            "Epoch 6/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.5808 - accuracy: 0.6013\n",
            "Epoch 7/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.5452 - accuracy: 0.6126\n",
            "Epoch 8/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6362 - accuracy: 0.5764\n",
            "Epoch 9/9\n",
            "136/136 [==============================] - 140s 1s/step - loss: 1.6103 - accuracy: 0.5982\n",
            "34/34 [==============================] - 8s 236ms/step - loss: 1.7164 - accuracy: 0.5786\n"
          ]
        }
      ],
      "source": [
        "for num_words in [5000,10000,15000,20000]:\n",
        "  my_chart=my_chart.append(make_my_series(num_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOPGrm3Vv17n",
        "outputId": "a51471c8-ae2c-434d-fd8f-2607f6be31af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Complement Naive  DecisionTree  ...  lstm_epoch     naive\n",
            "5000           0.777521      0.628122  ...    0.586957  0.679463\n",
            "10000          0.778908      0.618409  ...    0.632747  0.658649\n",
            "15000          0.777983      0.620722  ...    0.577243  0.634135\n",
            "20000          0.776596      0.619796  ...    0.578631  0.623959\n",
            "\n",
            "[4 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "print(my_chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VCsB8nbFIccv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b00b37b4-ae2d-463b-d8b0-b651f6effc19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Complement Naive</th>\n",
              "      <th>DecisionTree</th>\n",
              "      <th>GradientBoosting</th>\n",
              "      <th>Linear SVC</th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>Voting</th>\n",
              "      <th>logistic</th>\n",
              "      <th>lstm</th>\n",
              "      <th>lstm_epoch</th>\n",
              "      <th>naive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5000</th>\n",
              "      <td>0.777521</td>\n",
              "      <td>0.628122</td>\n",
              "      <td>0.770120</td>\n",
              "      <td>0.783071</td>\n",
              "      <td>0.683164</td>\n",
              "      <td>0.824699</td>\n",
              "      <td>0.814986</td>\n",
              "      <td>0.508788</td>\n",
              "      <td>0.586957</td>\n",
              "      <td>0.679463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>0.778908</td>\n",
              "      <td>0.618409</td>\n",
              "      <td>0.770120</td>\n",
              "      <td>0.781684</td>\n",
              "      <td>0.690102</td>\n",
              "      <td>0.820999</td>\n",
              "      <td>0.820999</td>\n",
              "      <td>0.444496</td>\n",
              "      <td>0.632747</td>\n",
              "      <td>0.658649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15000</th>\n",
              "      <td>0.777983</td>\n",
              "      <td>0.620722</td>\n",
              "      <td>0.770583</td>\n",
              "      <td>0.785384</td>\n",
              "      <td>0.671138</td>\n",
              "      <td>0.825624</td>\n",
              "      <td>0.824699</td>\n",
              "      <td>0.518964</td>\n",
              "      <td>0.577243</td>\n",
              "      <td>0.634135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20000</th>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.619796</td>\n",
              "      <td>0.773358</td>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.681776</td>\n",
              "      <td>0.825162</td>\n",
              "      <td>0.823312</td>\n",
              "      <td>0.456984</td>\n",
              "      <td>0.578631</td>\n",
              "      <td>0.623959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Complement Naive  DecisionTree  ...  lstm_epoch     naive\n",
              "5000           0.777521      0.628122  ...    0.586957  0.679463\n",
              "10000          0.778908      0.618409  ...    0.632747  0.658649\n",
              "15000          0.777983      0.620722  ...    0.577243  0.634135\n",
              "20000          0.776596      0.619796  ...    0.578631  0.623959\n",
              "\n",
              "[4 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "my_chart"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lstm 을 이용한 모델은 vocab 사이즈가 커질수록 학습에 어려움을 느낌.  \n",
        "lstm 은 다른 전처리 과정을 거침. TF-IDF Matrix을 사용하지 않음.  \n",
        "에폭이 상승할 수록 학습이 되는 것을 보였으나 에폭을 10회정도만 사용.   \n",
        "및 하이퍼파라미터의 변화를 주지 않음"
      ],
      "metadata": {
        "id": "rf3YcyB1fjrN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "dp_four.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOE/sP3EcChHPbsFNPhUsbW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}